{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mx.module.Module.load('demo3', 0, context=mx.gpu(0))\n",
    "model.bind([('data', (1, 3, 112, 112))], None, for_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/wuyuxiang/faces_ms1m_112x112/' + 'agedb_30.bin'\n",
    "bins, issame_list = pickle.load(open(path, 'rb'))\n",
    "data_list = []\n",
    "for flip in [0, 1]:\n",
    "    data = mx.nd.empty((len(issame_list) * 2, 3, 112, 112))\n",
    "    data_list.append(data)\n",
    "for i in range(len(issame_list) * 2):\n",
    "    _bin = bins[i]\n",
    "    img = mx.image.imdecode(_bin)\n",
    "    img = mx.nd.transpose(img, axes=(2, 0, 1))\n",
    "    for flip in [0, 1]:\n",
    "        if flip == 1:\n",
    "            img = mx.nd.flip(data=img, axis=2)\n",
    "        data_list[flip][i] = img\n",
    "    if i % 1000 == 0:\n",
    "        print('loading bin', i)\n",
    "print(data_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data_list[0][0].asnumpy()\n",
    "img = img[np.newaxis, :, :, :]\n",
    "img = mx.nd.array(img) \n",
    "db = mx.io.DataBatch(data=(img,), provide_data=[('data', (1, 3, 112, 112))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(db, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.get_outputs()[0] / mx.nd.norm(model.get_outputs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.get_outputs()[0] / mx.nd.norm(model.get_outputs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.nd.sum(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_list[0])):\n",
    "    img = data_list[0][i].asnumpy()\n",
    "    img = img[np.newaxis, :, :, :]\n",
    "    img = mx.nd.array(img) \n",
    "    db = mx.io.DataBatch(data=(img,), provide_data=[('data', (1, 3, 112, 112))])\n",
    "    model.forward(db)\n",
    "    b = model.get_outputs()[0] / mx.nd.norm(model.get_outputs()[0])\n",
    "    print(mx.nd.sum(a*b))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaFace GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(data, num_filter, kernel, name, stride=(1,1), slope=0.1, use_px=False):\n",
    "    pad = (kernel[0]//2, kernel[1]//2)\n",
    "    num_filter = num_filter*4 if use_px else num_filter\n",
    "    conv = mx.sym.Convolution(data, kernel=kernel, pad=pad, stride=stride, num_filter=num_filter, name='conv'+name)\n",
    "    IN = mx.sym.InstanceNorm(conv, name='conv_IN'+name)\n",
    "    out = mx.sym.LeakyReLU(IN, act_type='leaky', slope=0.1, name='act'+name)\n",
    "    if use_px:\n",
    "        px1 = mx.sym.reshape(act, shape=(0, -4, 2, 2, -2), name='px1_'+name) # (B, C, 2, 2, H, W)\n",
    "        px2 = mx.sym.transpose(px1, axes=(0, 1, 4, 2, 5, 3), name='px2_'+name) # (B, C, H, 2, W, 2)\n",
    "        out = mx.sym.reshape(px2, shape=(0, 0, -3, -3), name='px3_'+name) # (B, C, H*2, W*2)\n",
    "    return out\n",
    "def fc(data, num_hidden, name):\n",
    "    fc1 = mx.sym.FullyConnected(data, num_hidden=num_hidden, no_bias=True, name='fc'+name)\n",
    "    IN = mx.sym.InstanceNorm(fc1, name='fc_IN'+name)\n",
    "    out = mx.sym.Activation(IN, act_type='relu', name='act'+name)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_decoder():\n",
    "    # Input face (B, 3, 112, 112)\n",
    "    real_faces = mx.sym.Variable(name='real_faces_decoder')\n",
    "    # Input vec (B, 512)\n",
    "    vec = mx.sym.Variable(name='decoder_vec')\n",
    "    vec_reshape0 = mx.sym.reshape(vec, shape=(0, 0, 1, 1), name='decoder_vec_reshape0')\n",
    "    vec_norm0 = mx.sym.L2Normalization(vec_reshape0, mode='instance', name='decoder_vec_norm0')\n",
    "    # 1. Deconv (B, 512, 7, 7)\n",
    "    deconv1 = mx.sym.Deconvolution(vec_norm0, kernel=(7,7), num_filter=512, no_bias=True, name='decoder_deconv1')\n",
    "    deconv_IN1 = mx.sym.InstanceNorm(deconv1, name='decoder_deconv_IN1')\n",
    "    deconv_act1 = mx.sym.LeakyReLU(deconv_IN1, act_type='leaky', slope=0.1, name='decoder_deconv_act1')\n",
    "    # 2. PX (B, 256, 14, 14)\n",
    "    px2 = conv(deconv_act1, 256, kernel=(3,3), name='decoder_2', use_px=True)\n",
    "    # 3. PX (B, 128, 28, 28)\n",
    "    px3 = conv(px2, 128, kernel=(3,3), name='decoder_3', use_px=True)\n",
    "    # 4. PX (B, 64, 56, 56)\n",
    "    px4 = conv(px3, 64, kernel=(3,3), name='decoder_4', use_px=True)\n",
    "    # 5. PX (B, 32, 112, 112)\n",
    "    px5 = conv(px4, 32, kernel=(3,3), name='decoder_5', slope=0.2, use_px=True)\n",
    "    # 6. Conv(B, 32, 112, 112) 5x5\n",
    "    conv6 = conv(px5, 32, kernel=(5,5), name='decoder_6', slope=0.2, use_px=False)\n",
    "    # 7. mask(B, 1, 112, 112)\n",
    "    mask1 = mx.sym.Convolution(conv6, kernel=(5,5), pad=(2,2), stride=(1,1), num_filter=1, name='decoder_mask_conv')\n",
    "    mask = mx.sym.sigmoid(mask1, name='decoder_mask_conv_sigmoid')\n",
    "    # 7. bgr(B, 3, 112, 112)\n",
    "    bgr1 = mx.sym.Convolution(conv6, kernel=(5,5), pad=(2,2), stride=(1,1), num_filter=3, name='decoder_bgr_conv')\n",
    "    bgr = mx.sym.tanh(bgr1, name='decoder_bgr_conv_tanh')\n",
    "    # 8. mask*bgr + (1-mask)*real_faces\n",
    "    fake = mx.sym.broadcast_mul(mask, bgr) + mx.sym.broadcast_mul(mx.sym.broadcast_sub(1, mask), real_faces)\n",
    "    return fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discr1():\n",
    "    # lam (B, 1)\n",
    "    lam = mx.sym.Variable(name='d1_lam')\n",
    "    # fake (B, 3, 112, 112)\n",
    "    fake = mx.sym.Variable(name='d1_fake')\n",
    "    # real_faces (B, 3, 112, 112)\n",
    "    real_faces = mx.sym.Variable(name='d1_real_faces')\n",
    "    # d1_input = lam*concat(real, real) + (1-lam)*(fake, real)  ==>  (B, 6, 112, 112)\n",
    "    d1_input = mx.sym.broadcast_mul(lam, mx.sym.concat(real, real, dim=1)) + mx.sym.broadcast_mul(mx.sym.broadcast_sub(1, lam), mx.sym.concat(fake, real_faces, dim=1))\n",
    "    # 1. Conv(3, 64, 64)\n",
    "    conv1 = conv(d1_input, 3, kernel=(3,3), stride=(2,2), slope=0.2, name='discr1_1', use_px=False)\n",
    "    # 2. Conv(64, 32, 32)\n",
    "    conv2 = conv(conv1, 64, kernel=(3,3), stride=(2,2), slope=0.2, name='discr1_2', use_px=False)\n",
    "    # 3. Conv(128, 16, 16)\n",
    "    conv3 = conv(conv2, 128, kernel=(3,3), stride=(2,2), slope=0.2 name='discr1_3', use_px=False)\n",
    "    # 4. Conv(256, 8, 8)\n",
    "    conv4 = conv(conv3, 256, kernel=(3,3), stride=(2,2), slope=0.2, name='discr1_4', use_px=False)\n",
    "    # 5. Conv(512, 4, 4)\n",
    "    out = conv(conv4, 512, kernel=(3,3), stride=(2,2), slope=0.2, name='discr1_5', use_px=False)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator 2 (perceptual adversarial loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discr2():\n",
    "    # d2_input (B, 3, 112, 112)\n",
    "    d2_input = mx.sym.Variable(name='d2_input')\n",
    "    # 1. Conv55 (B, 32, 64, 64) 0.1\n",
    "    conv1 = conv(d2_input, 32, kernel=(5,5), stride=(2,2), slope=0.1, name='discr2_1', use_px=False)\n",
    "    # 2. Conv (B, 64, 32, 32) 0.1\n",
    "    conv2 = conv(conv1, 64, kernel=(3,3), stride=(2,2), slope=0.1, name='discr2_2', use_px=False)\n",
    "    # 3. Conv (B, 128, 16, 16) 0.2\n",
    "    conv3 = conv(conv2, 128, kernel=(3,3), stride=(2,2), slope=0.2, name='discr2_3', use_px=False)\n",
    "    # 4. Conv (B, 256, 8, 8) 0.2\n",
    "    conv4 = conv(conv3, 256, kernel=(3,3), stride=(2,2), slope=0.2, name='discr2_4', use_px=False)\n",
    "    # 5. Conv (B, 512, 4, 4) 0.2\n",
    "    conv5 = conv(conv4, 512, kernel=(3,3), stride=(2,2), slope=0.2, name='discr2_5', use_px=False)\n",
    "    # 6. Conv33 (B, 1, 4, 4)\n",
    "    conv6 = mx.sym.Convolution(conv5, num_filter=1, kernel=(3,3), stride=(1,1), pad=(1,1), name='discr2_6')\n",
    "    \n",
    "    out = mx.sym.Group([conv3, conv4, conv5, conv6])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discr3():\n",
    "    # d3_input (B, 512)\n",
    "    d3_input = mx.sym.Variable(name='d3_input')\n",
    "    # 1. fc (B, 256)\n",
    "    fc1 = fc(d3_input, 256, 'discr3_1')\n",
    "    # 2. fc (B, 128)\n",
    "    fc2 = fc(fc1, 128, 'discr3_2')\n",
    "    # 3. fc (B, 32)\n",
    "    fc3 = fc(fc2, 32, 'discr3_3')\n",
    "    # 4. fc (B, 1)\n",
    "    fc4 = fc(fc3, 1, 'discr3_4')\n",
    "    \n",
    "    return fc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_module():\n",
    "    # d1 output  [(B, 512, 4, 4)] [0]\n",
    "    d1_output = mx.sym.Variable('d1_output')\n",
    "    # d2 output  [(B, 128, 16, 16), (B, 256, 8, 8), (B, 512, 4, 4), (B, 1, 4, 4)]\n",
    "    d2_output0 = mx.sym.Variable('d2_output0')\n",
    "    d2_output1 = mx.sym.Variable('d2_output1')\n",
    "    d2_output2 = mx.sym.Variable('d2_output2')\n",
    "    d2_output3 = mx.sym.Variable('d2_output3')\n",
    "    # d3 output  [(B, 1)]\n",
    "    d3_output = mx.sym.Variable('d3_output')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face recognition",
   "language": "python",
   "name": "fr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
